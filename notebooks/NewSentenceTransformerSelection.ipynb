{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m165.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m147.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.24.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.24.1)\n",
      "Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "Successfully installed pyarrow-17.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22889,
     "status": "ok",
     "timestamp": 1729703395951,
     "user": {
      "displayName": "Francesco Buda",
      "userId": "00104607221776666637"
     },
     "user_tz": -120
    },
    "id": "-35vCL3oCPci",
    "outputId": "e29f9d55-b30e-4f01-8b27-8db257b7928c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tC562UhEDM0b"
   },
   "source": [
    "# IMPORT CODICI E FILTRAGGIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2044,
     "status": "ok",
     "timestamp": 1729703397991,
     "user": {
      "displayName": "Francesco Buda",
      "userId": "00104607221776666637"
     },
     "user_tz": -120
    },
    "id": "3julGMgIDQFS"
   },
   "outputs": [],
   "source": [
    "d_icd_diagnoses = pd.read_csv(\"./../data/d_icd_diagnoses.csv.gz\", compression=\"gzip\")\n",
    "d_icd10_diagnoses = d_icd_diagnoses[d_icd_diagnoses.icd_version==10]\n",
    "\n",
    "mimicCodes = set(d_icd10_diagnoses[\"icd_code\"].apply(lambda x: x.replace('.', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1729703397992,
     "user": {
      "displayName": "Francesco Buda",
      "userId": "00104607221776666637"
     },
     "user_tz": -120
    },
    "id": "-Us_W0SsDR_q"
   },
   "outputs": [],
   "source": [
    "def read_order(file_path):\n",
    "    dati = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            splitted = list(filter(None, line.split(\" \")))[1:3]\n",
    "            dati.append((splitted[0], True if splitted[1] == '1' else False))\n",
    "    df = pd.DataFrame(dati, columns=['Codice', 'Flag'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1081,
     "status": "ok",
     "timestamp": 1729703399071,
     "user": {
      "displayName": "Francesco Buda",
      "userId": "00104607221776666637"
     },
     "user_tz": -120
    },
    "id": "ML1JSNuGDTXp"
   },
   "outputs": [],
   "source": [
    "file_path = './../data/2020order.txt'\n",
    "assignableCodes = read_order(file_path)\n",
    "assignableCodes = set(assignableCodes[assignableCodes[\"Flag\"] == True][\"Codice\"])\n",
    "filtered_mimicCodes = mimicCodes.intersection(assignableCodes)\n",
    "codes = list(filtered_mimicCodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LI7S6kxDZad"
   },
   "source": [
    "# FUNZIONI UTILI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1729703399071,
     "user": {
      "displayName": "Francesco Buda",
      "userId": "00104607221776666637"
     },
     "user_tz": -120
    },
    "id": "HbokKywVDbrZ"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(\n",
    "    text: str,\n",
    "    lower: bool = True,\n",
    "    remove_special_characters_mullenbach: bool = True,\n",
    "    remove_special_characters: bool = False,\n",
    "    remove_digits: bool = True,\n",
    "    remove_accents: bool = False,\n",
    "    remove_brackets: bool = False,\n",
    "    convert_danish_characters: bool = False\n",
    ") -> str:\n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "    if convert_danish_characters:\n",
    "        text = re.sub(\"å\", \"aa\", text)\n",
    "        text = re.sub(\"æ\", \"ae\", text)\n",
    "        text = re.sub(\"ø\", \"oe\", text)\n",
    "    if remove_accents:\n",
    "        text = re.sub(\"é|è|ê\", \"e\", text)\n",
    "        text = re.sub(\"á|à|â\", \"a\", text)\n",
    "        text = re.sub(\"ô|ó|ò\", \"o\", text)\n",
    "    if remove_brackets:\n",
    "        text = re.sub(\"\\[[^]]*\\]\", \"\", text)\n",
    "    if remove_special_characters:\n",
    "        text = re.sub(\"\\n|/|-\", \" \", text)\n",
    "        text = re.sub(\"[^a-zA-Z0-9 .]\", \"\", text)  # Mantiene i punti\n",
    "    if remove_special_characters_mullenbach:\n",
    "        text = re.sub(\"[^A-Za-z0-9.]+\", \" \", text)  # Mantiene i punti\n",
    "    if remove_digits:\n",
    "        text = re.sub(\"(\\s\\d+)+\\s\", \" \", text)\n",
    "\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1729703399071,
     "user": {
      "displayName": "Francesco Buda",
      "userId": "00104607221776666637"
     },
     "user_tz": -120
    },
    "id": "Y9HoXIqSDgrz"
   },
   "outputs": [],
   "source": [
    "# DICTIONARY CODE -> DESCRIPTION\n",
    "cod2lbl = {}\n",
    "for key, value in zip(d_icd10_diagnoses.icd_code, d_icd10_diagnoses.long_title):\n",
    "    cod2lbl[key]=value\n",
    "\n",
    "# DICTIONARY DESCRIPTION -> CODE\n",
    "lbl2cod = {}\n",
    "for key, value in zip(d_icd10_diagnoses.long_title, d_icd10_diagnoses.icd_code):\n",
    "    lbl2cod[key]=value\n",
    "\n",
    "# FUNCTION TO ASSIGN DESCRIPTION TO CODES\n",
    "def assign_title(x):\n",
    "    return [cod2lbl[el.replace('.', '')] for el in x]\n",
    "\n",
    "# FUNCTION TO ASSIGN CODES TO DESCRIPTION\n",
    "def assign_codes(x):\n",
    "    return [lbl2cod[el] for el in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1729703399071,
     "user": {
      "displayName": "Francesco Buda",
      "userId": "00104607221776666637"
     },
     "user_tz": -120
    },
    "id": "ZwO4NpMIDifN"
   },
   "outputs": [],
   "source": [
    "def textToSentences(text):\n",
    "  sentences = sent_tokenize(text)\n",
    "  new_sentences = []\n",
    "  for sentence in sentences:\n",
    "    if len(sentence.split()) > 30:\n",
    "      words = sentence.split()\n",
    "      sub_sentences = [\" \".join(words[i:i+10]) for i in range(0, len(words), 10)]\n",
    "    else:\n",
    "      new_sentences.append(sentence)\n",
    "  return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Qs87Ru7DmSu"
   },
   "source": [
    "# IMPORT NOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1156,
     "status": "ok",
     "timestamp": 1729703400224,
     "user": {
      "displayName": "Francesco Buda",
      "userId": "00104607221776666637"
     },
     "user_tz": -120
    },
    "id": "GoTr9YB8G85B"
   },
   "outputs": [],
   "source": [
    "# MIMIC-IV SPLITS\n",
    "split = pd.read_feather(\"./../mimicSplits/mimiciv_icd10/mimiciv_icd10_split.feather\")\n",
    "train = split[split[\"split\"] == \"train\"]\n",
    "val = split[split[\"split\"] == \"val\"]\n",
    "test = split[split[\"split\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 20692,
     "status": "ok",
     "timestamp": 1729703420913,
     "user": {
      "displayName": "Francesco Buda",
      "userId": "00104607221776666637"
     },
     "user_tz": -120
    },
    "id": "iv-54cBSDoCM"
   },
   "outputs": [],
   "source": [
    "# MIMIC-IV ELABORATED TABLES\n",
    "icd10_df = pd.read_feather(\"./../data/mimiciv_icd10.feather\")\n",
    "\n",
    "#icd10_train_df = icd10_df[icd10_df['_id'].isin(train['_id'])].reset_index(drop=True)\n",
    "#icd10_val_df = icd10_df[icd10_df['_id'].isin(val['_id'])].reset_index(drop=True)\n",
    "icd10_test_df = icd10_df[icd10_df['_id'].isin(test['_id'])].reset_index(drop=True)\n",
    "\n",
    "icd10_df = icd10_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1729703420913,
     "user": {
      "displayName": "Francesco Buda",
      "userId": "00104607221776666637"
     },
     "user_tz": -120
    },
    "id": "Rmt5HirADpuj"
   },
   "outputs": [],
   "source": [
    "test = icd10_df.sample(20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imFE1wRjDwhX"
   },
   "source": [
    "# IMPORT SCISPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 18133,
     "status": "ok",
     "timestamp": 1729704268244,
     "user": {
      "displayName": "Francesco Buda",
      "userId": "00104607221776666637"
     },
     "user_tz": -120
    },
    "id": "lrjR1VYIDy1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip install scispacy\n",
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_sm-0.5.4.tar.gz\n",
    "\n",
    "import spacy\n",
    "import scispacy\n",
    "from scispacy.linking import EntityLinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 105863,
     "status": "ok",
     "timestamp": 1729704374103,
     "user": {
      "displayName": "Francesco Buda",
      "userId": "00104607221776666637"
     },
     "user_tz": -120
    },
    "id": "BZXAoRYID12i",
    "outputId": "57206b2a-34d5-4a3b-a1a3-2829062fc565"
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.9\n",
    "# Carica un modello pre-addestrato\n",
    "nlp = spacy.load(\"en_core_sci_sm\")\n",
    "nlp.add_pipe(\"scispacy_linker\", config={\"resolve_abbreviations\": True, \"linker_name\": \"umls\", \"threshold\" : THRESHOLD})\n",
    "linker = nlp.get_pipe(\"scispacy_linker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to empty gpu if OOM after generation (to avoid data cleaning and reloading of the notebook)\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "from huggingface_hub import login\n",
    "access_token = \"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\"\n",
    "login(access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# Create a sampling params object.\n",
    "sampling_params = SamplingParams(\n",
    "    n=1,\n",
    "    temperature=0.0,\n",
    "    top_p=1.0,\n",
    "    max_tokens=1024,\n",
    "    use_beam_search=False,\n",
    ")\n",
    "\n",
    "# Create an LLM.\n",
    "llm = LLM(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\", # switch to \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "    gpu_memory_utilization=.95,\n",
    "    dtype=\"auto\", # set to \"auto\" with L4 GPU\n",
    "    enforce_eager=True,\n",
    "    max_model_len=7000,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama_entities(text):\n",
    "\n",
    "  exampleTerms = \"- enlarged right testicle\\n- exposure to Brucella\\n- edema\\n- pain\\n- Brucella\\n- varicose veins\\n- jugular vein engorgement\\n- fever\\n- febrile syndrome\\n- orchiepididymitis\\n- osteoarticular pain\"\n",
    "  exampleText = \"We describe the case of a 37-year-old man with a previously active lifestyle, reporting osteoarticular pain of variable location over the past month and fever in the past week, with peaks (morning and evening) of 40°C in the last 24-48 hours, for which he visited the Emergency Department. Prior to the onset of symptoms, he had been in Extremadura, in a region endemic to brucella, consuming unpasteurized goat milk and cheese from the same livestock. Several cases of brucellosis were reported among the diners. During hospitalization for the study of the febrile syndrome with epidemiological history of possible exposure to Brucella, he developed a case of right orchiepididymitis.\\n\\nPhysical examination reveals: Temperature: 40.2°C; Blood pressure: 109/68 mmHg; Heart rate: 105 bpm. He is conscious, oriented, sweaty, eupneic, and in good nutritional and hydration status. No adenopathy, goiter, or jugular vein engorgement is palpated in the head and neck, with symmetrical carotid pulses. Cardiac auscultation reveals rhythmic heart sounds without murmurs, rubs, or extra sounds. Pulmonary auscultation shows preservation of vesicular breath sounds. The abdomen is soft, depressible, with no masses or organomegaly. Neurological examination does not detect meningeal signs or focal neurological data. The extremities show no varicose veins or edema. Peripheral pulses are present and symmetrical. Urological examination reveals the right testicle is enlarged, not adherent to the skin, with fluctuation areas and intensely painful on palpation, with loss of the epididymo-testicular boundary and positive transillumination.\\n\\nAnalytical data show the following results: Blood count: Hb 13.7 g/dl; leukocytes 14,610/mm³ (neutrophils 77%); platelets 206,000/mm³. ESR: 40 mm in the first hour. Coagulation: Prothrombin time 87%; APTT 25.8 seconds. Biochemistry: Glucose 117 mg/dl; urea 29 mg/dl; creatinine 0.9 mg/dl; sodium 136 mEq/l; potassium 3.6 mEq/l; AST 11 U/l; ALT 24 U/l; GGT 34 U/l; alkaline phosphatase 136 U/l; calcium 8.3 mg/dl. Urine: normal sediment.\\n\\nDuring hospitalization, blood cultures were requested: positive for Brucella, and specific serologies for Brucella: Rose Bengal +++; Coombs test > 1/1280; Brucellacapt > 1/5120. The requested imaging tests (chest X-ray, abdominal ultrasound, cranial CT, transthoracic echocardiogram) did not show significant pathology, except for the testicular ultrasound, which showed thickening of the scrotal sac with a small amount of fluid with septations and an enlarged testicle with small hypoechoic areas inside that could represent microabscesses.\\n\\nWith the diagnosis of orchiepididymitis secondary to Brucella, symptomatic treatment (antipyretics, anti-inflammatories, rest, and testicular elevation) was initiated, as well as specific antibiotic treatment: Doxycycline 100 mg orally every 12 hours (for 6 weeks) and Streptomycin 1 gram intramuscularly every 24 hours (for 3 weeks). The patient showed significant improvement after one week of hospitalization, and discharge was decided, with the patient completing the antibiotic treatment at home. In successive follow-up consultations, complete resolution of the condition was confirmed.\"\n",
    "\n",
    "\n",
    "  prompts = []\n",
    "  prompt = [\n",
    "    {\"role\": \"system\", \"content\": \"you are a medical expert\"},\n",
    "    {\"role\": \"user\", \"content\": \"read carefully the following medical note, then i'll tell you what to do.\\n\\nMedical Note:\\n\\\"\" + text + \"\\\"\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Ok, I've read carefully the content of the medical note.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Extract all the most important medical terms from the note and write them in this format:\\n- Term1\\n- Term2\\n- Term3\\n...\\n\\n. Do not include any additional text.\\n\\nHere is an example to help you understand the task:\\n\\nExample Note:\\n\\\"\" + exampleText + \"\\\"\\n\\nExample terms:\\n\"+ exampleTerms }\n",
    "  ]\n",
    "  prompts.append(prompt)\n",
    "\n",
    "  tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\") # switch to \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "  prompts = [tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True) for prompt in prompts]\n",
    "\n",
    "  BATCH_SIZE = 1 # number of prompts to process simultaneously (need to speed up generation)\n",
    "  prompts_batched = [prompts[i:i+BATCH_SIZE] for i in range(0, len(prompts), BATCH_SIZE)]\n",
    "\n",
    "  for id_batch, batch in enumerate(tqdm(prompts_batched, desc=\"Batches processed\")):\n",
    "    outputs = llm.generate(batch, sampling_params, use_tqdm=False)\n",
    "    # Print the outputs.\n",
    "    for i, output in enumerate(outputs):\n",
    "        prompt = output.prompt\n",
    "        generated_text = output.outputs[0].text\n",
    "        terms = generated_text.split(\"\\n- \")\n",
    "        print(terms)\n",
    "        return terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hFvZ-JlD8C-"
   },
   "source": [
    "# IMPORT TOKENIZER E SENTENCE TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, nltk\n",
      "Successfully installed nltk-3.9.1 regex-2024.9.11\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2819,
     "status": "ok",
     "timestamp": 1729704003588,
     "user": {
      "displayName": "Francesco Buda",
      "userId": "00104607221776666637"
     },
     "user_tz": -120
    },
    "id": "h4KExIYXD_pl",
    "outputId": "07cdbbee-6044-49e3-b684-01706ddeecd0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 49279,
     "status": "ok",
     "timestamp": 1729704052865,
     "user": {
      "displayName": "Francesco Buda",
      "userId": "00104607221776666637"
     },
     "user_tz": -120
    },
    "id": "ytbHjdjWECIC"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('alecocc/icd10-hard-negatives')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmYXgTefEMuO"
   },
   "source": [
    "# SELEZIONE CODICI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "z7cPQhXeEOsS"
   },
   "outputs": [],
   "source": [
    "titles = [cod2lbl[x] for x in codes]\n",
    "embeddings2 = model.encode(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "AovmQiPREQJa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of targetNames in selectedCodes: 0.00%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 60.00%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 55.56%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 60.00%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 63.64%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 66.67%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 50.00%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 58.33%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 66.67%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 75.00%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 51.61%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 38.46%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 50.00%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 53.33%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 71.43%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 42.11%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 51.72%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 57.14%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 48.28%\n",
      "num of selected codes: 100\n",
      "Percentage of targetNames in selectedCodes: 78.57%\n",
      "num of selected codes: 100\n",
      "mean percentage: 54.9257240590008\n",
      "mean num of selected codes: 100.0\n"
     ]
    }
   ],
   "source": [
    "meanPercentage = 0\n",
    "meanNumCodes = 0\n",
    "\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "  selectedCodes = set()\n",
    "  targetNames = set(assign_title(list(row[\"icd10_diag\"])))\n",
    "  note = row[\"raw_text\"]\n",
    "  sentences = textToSentences(note)\n",
    "\n",
    "\n",
    "\n",
    "  #entities = set()\n",
    "\n",
    "  #noteEntities = set(nlp(note).ents)\n",
    "  #for entity in noteEntities:\n",
    "  # ents = entity._.kb_ents\n",
    "  # for umls_ent in ents:\n",
    "  #   x = linker.kb.cui_to_entity[umls_ent[0]]\n",
    "  #   name = x.canonical_name\n",
    "  #   entities.add(name)\n",
    "  #   synonyms = x.aliases\n",
    "     #for synonym in synonyms:\n",
    "      #entities.add(synonym)\n",
    "\n",
    "\n",
    "  #for sentence in sentences:\n",
    "  #    sentenceEntities = set(nlp(sentence).ents)\n",
    "  #    for word in sentence.split():\n",
    "  #      sentenceEntities.update(set(nlp(word).ents))\n",
    "  #    for entity in sentenceEntities:\n",
    "  #      ents = entity._.kb_ents\n",
    "  #      for umls_ent in ents:\n",
    "  #        x = linker.kb.cui_to_entity[umls_ent[0]]\n",
    "  #        name = x.canonical_name\n",
    "  #        entities.add(name)\n",
    "  \n",
    "          #synonyms = x.aliases\n",
    "          #for synonym in synonyms:\n",
    "          #  entities.add(synonym)\n",
    "\n",
    "  entities = get_llama_entities(note)\n",
    "  entities = list(entities)\n",
    "  if(len(entities) > 0):\n",
    "      embeddings1 = model.encode(entities)\n",
    "    \n",
    "      similarity = model.similarity(embeddings1, embeddings2)\n",
    "    \n",
    "      maxvals = np.zeros(similarity.shape[1])\n",
    "      for i in range(similarity.shape[1]):\n",
    "        colonna = similarity[:, i].cpu().numpy()\n",
    "        maxvals[i] = np.max(colonna)\n",
    "    \n",
    "      maxvals = np.argsort(maxvals)[::-1][:100]\n",
    "      selectedCodes = set([titles[i] for i in maxvals])\n",
    "    \n",
    "      intersection = targetNames.intersection(selectedCodes)\n",
    "      percentage = (len(intersection) / len(targetNames)) * 100\n",
    "      print(f\"Percentage of targetNames in selectedCodes: {percentage:.2f}%\")\n",
    "      print(f\"num of selected codes: {len(selectedCodes)}\")\n",
    "  else:\n",
    "      percentage = 0\n",
    "  meanPercentage += percentage\n",
    "  meanNumCodes += len(selectedCodes)\n",
    "\n",
    "print(f\"mean percentage: {meanPercentage / len(test)}\")\n",
    "print(f\"mean num of selected codes: {meanNumCodes / len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELEZIONE CODICI LLAMA"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO3nWTUnoBKoxylyjrlqrNK",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
